# MySQL/MariaDB Import Guide

This guide explains how to import the CSV files generated by the WOS XML Parser into a MySQL or MariaDB database.

## Prerequisites

1. **Database Server**: You need a running MySQL (version 5.7+) or MariaDB (version 10.3+) server
   - **Linux Debian users**: MariaDB is the default SQL server and is fully supported
   - **Other Linux distributions**: Both MySQL and MariaDB are supported
   
2. **MySQL/MariaDB Client**: The `mysql` or `mariadb` command-line client must be installed
   ```bash
   # For Debian/Ubuntu
   sudo apt-get install mysql-client
   # OR
   sudo apt-get install mariadb-client
   
   # For Red Hat/CentOS/Fedora
   sudo yum install mysql
   # OR
   sudo dnf install mariadb
   ```

3. **Python Package (Optional)**: Only needed if you want to run example queries using Python:
   ```bash
   pip install pymysql
   ```

## Quick Start

### 1. Generate CSV Files

First, run the XML parser to generate CSV files:

```bash
cd for_xml
python xml_proc_main.py path/to/xml/files/
```

This will create 33 CSV files in the `xml_output` directory.

### 2. Import to MySQL/MariaDB

**Option 1: Using the convenience script (recommended)**

```bash
./import_csv_to_mysql.sh [mysql_password] [database_name]

# Example
./import_csv_to_mysql.sh mypassword wos_xml
```

**Option 2: Using SQL commands directly**

```bash
# Step 1: Create database and tables
mysql -u root -p < create_database_and_tables.sql
# OR for MariaDB
mariadb -u root -p < create_database_and_tables.sql

# Step 2: Import CSV data (requires local-infile enabled)
mysql -u root -p --local-infile=1 < import_csv_data.sql
# OR for MariaDB
mariadb -u root -p --local-infile=1 < import_csv_data.sql
```

This will:
- Create a MySQL/MariaDB database named `wos_xml`
- Create 33 tables with proper schema and indexes
- Import all CSV files from the `xml_output` directory

## Advanced Usage

### Custom Database Configuration

The bash script supports environment variables:

```bash
# Specify custom host
DB_HOST=myserver ./import_csv_to_mysql.sh mypassword wos_xml

# Specify custom database name
./import_csv_to_mysql.sh mypassword my_wos_db

# Specify custom CSV directory
CSV_DIR=my_csv_dir ./import_csv_to_mysql.sh mypassword wos_xml
```

### Custom CSV Directory

If your CSV files are in a different location, either:

1. Use the `CSV_DIR` environment variable with the bash script:
   ```bash
   CSV_DIR=/path/to/csv/files ./import_csv_to_mysql.sh mypassword
   ```

2. Edit `import_csv_data.sql` to update the file paths

### Drop and Recreate Database

**WARNING**: This will delete all existing data in the database!

To drop and recreate the database, you can:

1. Manually drop it first:
   ```bash
   mysql -u root -p -e "DROP DATABASE IF EXISTS wos_xml;"
   ```

2. Then run the import script as normal

### Using Non-default Database Name

To use a different database name:

1. Edit `create_database_and_tables.sql` and replace all occurrences of `wos_xml` with your desired database name
2. Pass the new name to the import script:
   ```bash
   ./import_csv_to_mysql.sh mypassword my_custom_db_name
   ```

## Import Methods Comparison

| Method | Pros | Cons |
|--------|------|------|
| **Bash Script** | Simple, automated, handles both steps | Requires bash |
| **Direct SQL** | Full control, can customize easily | More manual steps |

## Database Schema

The script creates 33 tables organized into 6 sections:

### Section 1: Paper Basic Information (14 tables)
- `item` - Main paper metadata (PRIMARY KEY: uid)
- `item_title` - Paper titles
- `item_abstract` - Paper abstracts
- `item_doc_types` - Document types
- `item_doc_types_norm` - Normalized document types
- `item_langs` - Languages
- `item_langs_norm` - Normalized languages
- `item_editions` - WOS editions
- `item_keywords` - Keywords
- `item_keywords_plus` - Keywords Plus
- `item_source` - Source publication information
- `item_ids` - Identifiers (DOI, ISSN, etc.)
- `item_oas` - Open access information
- `item_publishers` - Publisher information

### Section 2: Author Information (12 tables)
- `item_authors` - Author names and details
- `item_addresses` - Author addresses
- `item_au_addrs` - Author-address relationships
- `item_addr_aus` - Address-author relationships
- `item_orgs` - Organizations
- `item_suborgs` - Sub-organizations
- `item_author_ids` - Author identifiers (ORCID, ResearcherID)
- `item_rp_addrs` - Reprint addresses
- `item_rp_au_addrs` - Reprint author-address relationships
- `item_rp_orgs` - Reprint organizations
- `item_rp_suborgs` - Reprint sub-organizations
- `item_contributors` - Contributors with IDs

### Section 3: Category Information (2 tables)
- `item_headings` - Research headings
- `item_subjects` - Research subjects

### Section 4: References (2 tables)
- `item_references` - Cited references
- `item_cite_locations` - Citation locations in text

### Section 5: Funding Information (2 tables)
- `item_acks` - Acknowledgments
- `item_grants` - Grant information

### Section 6: Conference Information (1 table)
- `item_conferences` - Conference details

## Table Relationships

- All tables (except `item`) have a foreign key reference to `item(uid)`
- Foreign keys are set with `ON DELETE CASCADE` for data integrity
- The `item` table must be populated first
- Appropriate indexes are created for common query patterns

## Performance Notes

- The SQL import uses `LOAD DATA LOCAL INFILE` for efficient bulk loading
- Foreign key checks are temporarily disabled during import for better performance
- Full-text indexes are created on `abstract` and `ack_text` fields for text search
- Appropriate indexes are created on commonly queried fields (uid, year, country, etc.)

## Character Encoding

- Database uses `utf8mb4` character set with `utf8mb4_unicode_ci` collation
- This supports full Unicode including emojis and special characters
- Proper handling of international author names and publication titles

## Troubleshooting

### Connection Issues

If you get connection errors:

**For MySQL:**
```bash
# Check if MySQL is running
sudo systemctl status mysql

# Verify credentials
mysql -u root -p
```

**For MariaDB (Debian/Ubuntu default):**
```bash
# Check if MariaDB is running
sudo systemctl status mariadb

# Verify credentials
mariadb -u root -p
# OR
mysql -u root -p  # mysql command works with MariaDB too
```

### LOAD DATA INFILE Issues

If you encounter "The used command is not allowed" errors:

1. **Enable local_infile in MySQL/MariaDB configuration:**

   Edit your MySQL/MariaDB configuration file:
   ```ini
   # /etc/mysql/my.cnf or /etc/mysql/mysql.conf.d/mysqld.cnf
   [mysqld]
   local_infile=1
   
   [mysql]
   local_infile=1
   ```

   Restart the server:
   ```bash
   sudo systemctl restart mysql
   # OR
   sudo systemctl restart mariadb
   ```

2. **Use --local-infile flag** when running the import:
   ```bash
   mysql -u root -p --local-infile=1 < import_csv_data.sql
   ```

3. **Check secure_file_priv setting:**
   ```sql
   SHOW VARIABLES LIKE 'secure_file_priv';
   ```
   
   If this is set to a specific directory, either:
   - Move your CSV files to that directory
   - Change the setting in configuration (requires server restart)
   - Set it to empty string to allow from any location

### File Path Issues

If CSV files are not found:

1. **Check that CSV files exist:**
   ```bash
   ls -la xml_output/
   ```

2. **Ensure paths in SQL script are correct:**
   The bash script automatically handles path resolution. If using SQL directly, verify paths in `import_csv_data.sql` match your CSV file locations.

3. **Use absolute paths** if relative paths don't work:
   Edit `import_csv_data.sql` and replace `xml_output/` with the full absolute path.

### Permission Issues

If you get permission errors, grant necessary privileges:

**For MySQL:**
```sql
-- Grant FILE privilege for LOAD DATA INFILE
GRANT FILE ON *.* TO 'username'@'localhost';
GRANT ALL PRIVILEGES ON wos_xml.* TO 'username'@'localhost';
FLUSH PRIVILEGES;
```

**For MariaDB:**
```sql
-- Same syntax works for MariaDB
GRANT FILE ON *.* TO 'username'@'localhost';
GRANT ALL PRIVILEGES ON wos_xml.* TO 'username'@'localhost';
FLUSH PRIVILEGES;
```

### MariaDB-Specific Notes

1. **Default Authentication**: On Debian/Ubuntu, MariaDB may use unix_socket authentication for root:
   ```bash
   # Connect as root without password (if using unix_socket)
   sudo mariadb
   
   # Create a user with password authentication
   CREATE USER 'wos_user'@'localhost' IDENTIFIED BY 'password';
   GRANT FILE ON *.* TO 'wos_user'@'localhost';
   GRANT ALL PRIVILEGES ON wos_xml.* TO 'wos_user'@'localhost';
   FLUSH PRIVILEGES;
   ```

2. **Compatibility**: The SQL scripts work with both MySQL and MariaDB
   - MariaDB is a drop-in replacement for MySQL
   - All SQL syntax used is compatible with both systems
   - Both `mysql` and `mariadb` command-line clients can be used

### Import Errors

Common issues during import:
- **Missing CSV files**: Make sure you ran the XML parser first
  ```bash
  python xml_proc_main.py path/to/xml/files/
  ```
- **Data type mismatches**: Check if CSV data matches expected schema
- **Foreign key violations**: Tables are imported in correct order to prevent this
- **Character encoding issues**: Make sure CSV files are UTF-8 encoded

### Large Datasets

For very large datasets:
- Consider increasing MySQL/MariaDB's `max_allowed_packet` setting
- Monitor disk space during import
- The import may take several minutes for large datasets

**MySQL configuration:**
```ini
# /etc/mysql/my.cnf or /etc/mysql/mysql.conf.d/mysqld.cnf
[mysqld]
max_allowed_packet=256M
```

**MariaDB configuration:**
```ini
# /etc/mysql/mariadb.conf.d/50-server.cnf
[mysqld]
max_allowed_packet=256M
```

## Querying the Database

After import, you can query the database:

```sql
USE wos_xml;

-- Count total papers
SELECT COUNT(*) FROM item;

-- Papers by year
SELECT pubyear, COUNT(*) as count 
FROM item 
GROUP BY pubyear 
ORDER BY pubyear DESC;

-- Top authors
SELECT full_name, COUNT(*) as papers 
FROM item_authors 
GROUP BY full_name 
ORDER BY papers DESC 
LIMIT 10;

-- Papers with abstracts
SELECT i.uid, i.pubyear, t.title, a.abstract 
FROM item i 
JOIN item_title t ON i.uid = t.uid 
JOIN item_abstract a ON i.uid = a.uid 
LIMIT 10;
```

### Running Example Queries

A comprehensive set of example queries is provided in `example_queries.py`:

```bash
# First install pymysql if not already installed
pip install -r requirements_mysql.txt

# Then run the example queries
python example_queries.py
```

This script demonstrates 15+ common queries including:
- Paper counts by year, country, organization
- Author and citation statistics
- Research subject analysis
- Funding and grant information
- Open access statistics

You can use these as templates for your own analysis.

## Security Considerations

1. **Passwords**: Avoid exposing passwords on the command line. Instead:
   - Let the bash script prompt for password interactively (don't pass it as argument)
   - Use MySQL configuration file (`~/.my.cnf`) with restricted permissions
   - Use environment variables

2. **Database Access**: Create a dedicated database user with minimal privileges:
   
   **For MySQL:**
   ```sql
   CREATE USER 'wos_importer'@'localhost' IDENTIFIED BY 'secure_password';
   GRANT FILE ON *.* TO 'wos_importer'@'localhost';
   GRANT SELECT, INSERT, CREATE, DROP ON wos_xml.* TO 'wos_importer'@'localhost';
   FLUSH PRIVILEGES;
   ```
   
   **For MariaDB:**
   ```sql
   -- Same syntax works for MariaDB
   CREATE USER 'wos_importer'@'localhost' IDENTIFIED BY 'secure_password';
   GRANT FILE ON *.* TO 'wos_importer'@'localhost';
   GRANT SELECT, INSERT, CREATE, DROP ON wos_xml.* TO 'wos_importer'@'localhost';
   FLUSH PRIVILEGES;
   ```

3. **File Permissions**: Ensure CSV files and SQL scripts have appropriate permissions:
   ```bash
   chmod 600 *.sql  # Only owner can read/write
   ```

4. **Database Deletion**: Be careful when dropping databases - this permanently deletes data

## Support

For issues or questions:
- Check the main README.md in the for_xml directory
- Review the tables.md file for detailed schema documentation
- Check database error logs:
  - MySQL: `/var/log/mysql/error.log`
  - MariaDB: `/var/log/mysql/error.log` or `/var/log/mariadb/mariadb.log`

## Compatibility Notes

The import script is fully compatible with both MySQL and MariaDB:
- **Tested with**: MySQL 5.7+, MySQL 8.0+, MariaDB 10.3+, MariaDB 10.5+, MariaDB 10.11+
- **Character encoding**: utf8mb4 with unicode collation (supports all international characters)
- **SQL syntax**: Uses standard SQL compatible with both database systems
- **Auto-detection**: Script automatically detects which database server you're using
- **Libraries**: Works with both `pymysql` and `mysqlclient` Python packages
